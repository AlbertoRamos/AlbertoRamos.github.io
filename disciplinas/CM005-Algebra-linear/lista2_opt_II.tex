% lista 1(optimization II 2017 II)
\documentclass[a4paper,latin]{article}
%\usepackage{amssymb,latexsym,amsthm,amsmath}
\usepackage[paper=a4paper,hmargin={1cm,1cm},vmargin={1.5cm,1.5cm}]{geometry}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage[utf8]{inputenc}

\begin{document}

\title{Lista 2: Otimização II }
 
\author{
A. Ramos \thanks{Department of Mathematics,
    Federal University of Paraná, PR, Brazil.
    Email: {\tt albertoramos@ufpr.br}.}
}

\date{\today}
 
\maketitle

\begin{abstract}
{\bf Lista em constante atualização}.
 \begin{enumerate}
 \item Gradiente conjugados
 \item Métodos de Região de Confiança.
 \item Para os exercícios que forem convenientes pode ser usado alguma linguagem  de programação.  
 \end{enumerate}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
%\section*{Elipse} 
%Seja $\mathcal{O}$ um aberto em $\mathbb{R}^{n}$. 
%Denote por 
%$C^{1,1}_{L}(\mathcal{O})$ o conjunto das funções deriváveis 
%em $\mathcal{O}$ cuja derivada é Lipschitziana com constante de 
%     Lipschitz $L$ em $\mathcal{O}$, isto é, 
%     $\|\nabla f(x)-\nabla f(y)\|\leq L\|x-y\|$, 
%     para todo $x,y \in \mathcal{O}$.
       
    \begin{enumerate}
    \item Seja $Q$ uma matriz simétrica definida positiva. Verifique 
    que no método de Gradiente Conjugados linear temos que para $k \geq 1$
    $$\text{span}\{r^{0}, r^{1}, r^2,  \dots, r^{k}\}=
    \text{span}\{d^{0}, d^{1}, d^2, \dots, d^{k}\}=
    \text{span}\{r^{0},  Qr^{0}, Q^{2} r^{0}, \dots, Q^{k} r^{0}\}.$$ 
    \item Encontre os mínimos das quadráticas usando método dos gradientes conjugados
       \begin{enumerate}
       	\item $q(x,y)=-xy+1-y+x^2+(1/2)y^2$, com $x^{0}=(0,0)^{T}$ 
       	\item $q(x,y)=-3x-4y-0.5+2xy+x^2+y^2$, com $x^0=(2,1)^{T}$
       \end{enumerate}
    \item  
    Suponha que o método de gradientes conjugados não linear é implementada de forma que o parâmetro do passo $\alpha_{k}$ satisfaz a condição forte de Wolfe, com $c_{2}\in (0,1/2)$, e que $|\beta_{k}|\leq \beta_{k}^{FR}$, $\forall k \in \mathbb{N}$. Então, mostre que 
    $$ -\frac{1}{1-c_2} \leq \frac{\nabla f(x^k)^{T}d^{k}}{\|\nabla f(x^k)\|^{2}} \leq \frac{2c_2-1}{1-c_2}, \text{ para } k=0,1,2, \dots,  $$
    Conclua que as direções $d^{k}$ são direções de descida.
    \item Considere $Q$ uma matriz simétrica definida positiva.
    Prove ou dê um contra-exemplo:
       \begin{enumerate}
       \item Se $Q$ é múltiplo da identidade, então as direções 
       $Q$-conjugadas são ortogonais
       \item Se $Q$ é diagonal, então as direções 
       $Q$-conjugadas são ortogonais
       \item Autovetores de $Q$ associados a autovalores distintos 
       são $Q$-conjugados.
       \end{enumerate}   
   \item Seja $Q$ uma matriz $n \times n$ simétrica definida positiva. Mostre que o método de gradiente conjugados linear resolve o sistema $Ax=b$, usando como máximo $n$ iterações. 
    \item Seja $Q$ uma matriz simétrica definida positiva e considere 
    $\{v^1,\dots,v^n\}$ uma família de vetores linearmente independentes. 
    Defina 
    $$d^{1}:=v^{1} \  \ \text{ e } \ \ 
    d^{k+1}:=v^{k+1}-\sum_{i=1}^{k} \theta^{k+1}_{i} d^{i},
    \ \ \text{ para } \ \ k=1,2,\dots, n-1, $$ 
    onde $\theta^{k+1}_{i}=(v^{k+1})^{T}Qd^i/(d^{i})^{T}Qd^{i}$. 
    Mostre que $\{d^1,\dots,d^n\}$ são $Q$-conjugados.
    \item Prove que para o método de Gradiente conjugados linear, 
    sempre temos que 
    $\langle d^{k}, A d^{k} \rangle=-\langle d^{k}, A g^{k} \rangle$, 
    onde $g^{k}:=\nabla q(x^k)$. %, $\forall k \in \mathbb{N}$.    
    \item Dado $n \in \mathbb{N}$. Considere a matriz $A$
    $n \times n$ e o vetor $b \in \mathbb{R}^{n}$  definidos como 
    $b_{i}=1$, $\forall i$ e $A_{ij}=\frac{1}{i+j-1}, \forall i,j$ (
    a matriz $A$ é chamada de {\it matriz de Hilbert}).
    Use o método de Gradiente conjugado, para resolver 
    $Ax=b$, com ponto inicial $x^{0}=0$ para diferente valores de 
    $n \in \mathbb{N}$, em especial, $n=5, 10, 20$.  
    
    {\it Observação:} A matriz de Hilbert é o exemplo clássico de matriz mal condicionada. 
    \item Mostre que $d^{*}$ é a solução do problema 
    $$
      \text{ min } m(d):=f+g^{T}d+\frac{1}{2} d^{T}Bd 
      \ \ \text{ sujeito a } \ \ 
      \|d\|_2 \leq \Delta, $$
    se, e somente se existe $\lambda\geq 0$ tal que 
    (i) $(B+\lambda I)d^{*}=-g$, (ii) $\|d^{*}\|\leq \Delta$, 
    (iii) $\lambda(\|d^*\|-\Delta)=0$ e (iv) $B+\lambda I$ é 
    uma matriz semi-definida positiva. 
    
    Conclua que se a solução otima $d^{*}$ está no interior da bola $\{d:\|d\|\leq \Delta\}$ temos que $\nabla m(d^*)=0$ e $B \succeq 0$ \footnote{Essa observação foi discutida em aula}.
    \item Considere o problema quadrático 
    $
    \text{ min } m(d):=f+g^{T}d+\frac{1}{2} d^{T}Bd 
    \ \ \text{ sujeito a } \ \ 
    \|d\|_2 \leq \Delta $. 
       \begin{enumerate}
       	\item Considere a decomposição espectral de $B$, 
       	$B=U ^{T}\Lambda U$, onde $U$ é uma matriz ortogonal, 
       	$\Lambda$ é uma matriz diagonal e $\lambda_i:=\Lambda_{ii}$.
       	Prove que se $\lambda>-\lambda_{min}(B)$, o sistema linear $(B+\lambda I)d=-g$ admite uma única solução 
       	denotado por $d(\lambda)$ e
       	 $$  \|d(\lambda)\|^{2}= \sum_{i=1}^{n} \frac{|(Ug)_i|^{2}}{(\lambda_i+\lambda)^2}.$$
       	\item {\it Nas mesmas hipóteses do item anterior}. Certamente, 
       	$\phi(\lambda):=\|d(\lambda)\|$ tem finitos polos mas não possui zeros. 
       	Assim, $\psi(\lambda):=1/\phi(\lambda)$ tem zeros mas não tem polos. Portanto em lugar de resolver $\|d(\lambda)\|-\Lambda=0$
       	é conveniente resolver $\frac{1}{\|d(\lambda)\|}-\frac{1}{\Lambda}=0$ (dita equação é chamada de {\it equação secular}). Usualmente para resolver a equação secular é usado o método de Newton. Assim,
       	   \begin{enumerate}
       	   	\item Verifique que $\nabla_{\lambda} d(\lambda)=-(B+\lambda)^{-1} d(\lambda)$
       	   	\item Mostre que a derivada de $\psi'(\lambda)$ é  $$\psi'(\lambda)=-\frac{\langle d(\lambda),
       	   	\nabla_{\lambda} d(\lambda)\rangle}{\|d(\lambda)\|^{3}}$$
          	\item Calcule  a segunda derivada de $\psi''(\lambda)$  $$\psi''(\lambda)=
          	-\frac{3(\langle d(\lambda),
          		\nabla_{\lambda} d(\lambda)\rangle^{2}-\|d(\lambda)\|^{2}\|\nabla_{\lambda} d(\lambda)\|^2)}{\|d(\lambda)\|^{5}}$$
          	\item Descreva o método de Newton desse caso.
       	   \end{enumerate}
       \end{enumerate}
    \item Resolva o sistema $Ax=b$ usando o método de gradientes conjugados com 
    $x^0=\begin{pmatrix}
    1/2 \\
    0 
    \end{pmatrix}$, onde 
    $A=\begin{pmatrix}
    	1 & 2 \\
    	2 & 6
    \end{pmatrix}$ e 
    $b=\begin{pmatrix}
    0 \\
    1 
    \end{pmatrix}$.
      
    \item ({\it Generalização do passo de Cauchy}.) Considere 
    $D$ uma matriz $n \times n$ defina positiva.
      \begin{enumerate}
      	\item Seja $d_{G}^{k}$ solução otima de 
      	$$ \text{ min } f(x^k)+ d^{T}g^{k} 
      	   \text{ sujeito a } \|Dd\|\leq \Delta. $$
      	   Prove que $d_{G}^{k}= -\frac{\Delta_k}{\|Dg^{k}\|} D^{-2}g^{k}$.
      	\item O passo de Cauchy Generalizado é definida como
      	$$ m_{k}(d_{CG}^{k})= \min \{ m_{k}(d): 
      	                      d=\tau d_{G}^{k}, \|D d\|\leq \Delta  
      	                      \}. $$
      	Assim, o passo de Cauchy Generalizado é
      	$$  d_{CG}^{k}=\tau_{k}d_{G}^{k}=-\tau_k \frac{\Delta_k}{\|Dg^{k}\|} D^{-2}g^{k},  $$                        
      	onde $\tau_{k}:=\text{ argmin } 
      	m_{k}(\tau d_{G}^{k}) \text{ s.a } \|\tau Dd_{G}^{k}\|\leq \Delta$.
      	Mostre a seguinte expressão para $\tau_{k}$
      	  $$
      	  \tau_{k}=
      	  \left\{
      	  \begin{matrix}
      	  1 & \text{ se } (g^{k})^{T}D^{-2}B_{k}D^{-2}g^{k}\leq 0 \\
      	  \min  \{ \frac{\|D^{-1}g^{k}\|^{3}}{\Delta_{k}(g^{k})^{T}D^{-2}B_{k}D^{-2}g^{k}}, 1\} & \text{ caso contrário }
      	  \end{matrix}
      	  \right.	  
      	  $$ 
      \end{enumerate}
        {\it Observação: } Se $D=I$, recuperamos o passo de Cauchy.	  
        %TRUST REGION MODIFICADO COM D diferente $\|Dd\|\leq\Delta$.
    % \item TWO STEP DOGLEG 
     \item Mostre as seguintes relações para o método de gradientes conjugados linear
    \begin{enumerate}
    	\item 
    	$$\alpha_{k}=
    	\frac{\|r^{k}\|^{2}}{\langle d^{k},Qd^{k}\rangle}=
    	-\frac{\langle r^{k},d^{k}\rangle}{\langle d^{k}, Qd^{k}\rangle}=
    	-\frac{\langle r^{0},d^{k}\rangle}{\langle d^{k}, Qd^{k}\rangle}$$
    	\item  
    	$$\beta_{k+1}=
    	\frac{\|r^{k+1}\|^{2}}{\|r\|^{k}}=
    	\frac{\langle r^{k+1},Qd^{k}\rangle}{\langle d^{k}, Qd^{k}\rangle}=
    	-\frac{\langle r^{k+1},Qr^{k}\rangle}{\langle d^{k}, Qd^{k}\rangle}$$
    \end{enumerate}    
    \item Considere os matrizes e vetores 
      
    $$
    Q=\begin{pmatrix}
    2 & 1 & -1 \\
    1 & 3 &  2 \\
    -1 & 2 & 4
    \end{pmatrix},  
    b=\begin{pmatrix}
    1 \\
    2 \\
    1
    \end{pmatrix}, 
    v=\begin{pmatrix}
    1 \\
    0 \\
    0
    \end{pmatrix}, 
    w=\begin{pmatrix}
    0 \\
    2 \\
    2
    \end{pmatrix}.$$
     \begin{enumerate}
     	\item Verifique de $v$ e $w$ são $Q$-conjugados
     	\item Minimize a função quadrática 
     	$q(x):=\frac{1}{2} x^{T}Qx-b^{T}x$ sobre o plano gerado pelos vetores $\{v,w\}$.
     	
     	{\it Dica: } Use como guia e informação o item anterior
     \end{enumerate}
    \item Considere a função $f:\mathbb{R} \rightarrow \mathbb{R}$
    $f(x):=x^{3}-x$. 
       \begin{enumerate}
       	\item Encontre todos os pontos máximos e mínimos (locais e globais) de $f$
       	\item Faça duas iterações do método de região de confiança para  o problema $\min f(x)$. Use $\Delta_{0}=1/4$ e $x^{0}=0$.
       \end{enumerate}
     \item Seja $f(x,y)=y^2+\frac{1}{2}x^2$ e $x^0=(1,1)^{T}$.
     Para $\Delta_0=1$ e $\Delta_0=5/4$. Use o método dogleg para encontrar $x^1$. 
    \item Seja $\{x^{k}\}$ uma sequência gerada pelo método de gradiente conjugados linear. Mostre que em cada nova iteração, o 
    iterado $x^{k}$ se aproxima (positivamente) à solução otima $x^{*}$, isto é, 
    $\|x^*-x^{k}\|$ é uma sequência {\it estritamente} decrescente.
    Para isso faça o seguinte:
      \begin{enumerate}
    	\item Mostre que $\langle d^{i}, d^{j}\rangle>0$, para 
    	$i \neq j$. 
    	\item Compare $\|x^*-x^{k}\|^{2}$ com $\|x^*-x^{k-1}\|^{2}$, 
    	escreva $x^{k}-x^{k-1}$ como combinação linear das direções $\{d^{i}\}$ e use o item anterior.  Conclua.   	
      \end{enumerate}	 
    \item \begin{enumerate}
    	  \item Descreva o método de região de confiança
    	  \end{enumerate}
      Considere as seguintes hipóteses
      
      {\bf (H1)}. A solução aproximada do modelo $d^{k}$
      satisfaz 
       $ 
      \text{ pred}_{k}=m_{k}(0)-m_{k}(d^{k}) \geq 
      c_1 \|g_k\|
      \min \{ \Delta_k, \frac{\|g_{k}\|}{\|B_k\|} \}
      $ para certo $c_1 \in (0,1)$.
      
      {\bf (H2)}. O passo $d^{k}$ satisfaz $\|d^k\|\leq \gamma \Delta_k$ para certo 
      	$\gamma\geq 1$.
      
      {\bf (H3)}. As hessianas $\{B_k\}$ são uniformemente limitadas por alguma constante $\beta$, i.e., $\|B_k\|\leq \beta$, $\forall k$. 
      	
         \begin{enumerate}
    	  \item Verifique que o passo de Cauchy 
    	$d_{C}^{k}$ satisfaz a desigualdade
    	   descrita em (H1) 
    	   com $c_{1}=1/2$. 
    	  \item Seja 
    	  $\{x^k\}$ uma sequência gerada pelo método de região de confiança.
    	  Mostre que se $f \in C^{1}$ e as hipóteses 
    	  (H1), (H2)
    	  e (H3) são satisfeitas. Então:
    	  $$
    	  |\rho_k-1|
    	  \leq 
   \frac{\gamma\Delta_{k}\left(\frac{\beta}{2}\gamma \Delta_k+\text{sup}_{\theta \in [0,1]}
    	  \|\nabla f(x^k+\theta_kd^k)
    	  -\nabla f(x^k)\|\right)}
    	  {c_1 \|g_k\| \min \{ \Delta_k, \frac{\|g_{k}\|}{\|B_k\|}\}}$$
    	  \item Usando  as mesma hipóteses do item anterior, conclua que 
    	  depois de um número finito de passo mal sucedidos, temos um passo bem sucedido. 
    	  \item   Seja 
    	  $\{x^k\}$ uma sequência gerada pelo método de região de confiança.
    	  Mostre que se $f \in C^{1}$ com $\nabla f$ uniformemente contínua e as hipóteses 
    	  (H1), (H2)
    	  e (H3) são satisfeitas. Então, $\liminf \nabla f(x^k)=0$.
    	  \item Seja 
    	  $\{x^k\}$ uma sequência gerada pelo método de região de confiança.
    	  Mostre que se $f \in C^{2}$ e as hipóteses 
    	  (H1), (H2)
    	  e (H3) são satisfeitas, com $B_{k}:=\nabla^2 f(x^k)$, $\forall k$.
    	  Então,  $\liminf \nabla f(x^k)=0$ e 
    	  $\liminf \lambda_{min}\nabla^{2} f(x^k)\geq 0$.
         \end{enumerate}
    \end{enumerate}

\end{document}

  
